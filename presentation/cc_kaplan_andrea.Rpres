<style>
.reveal section del,
.reveal h1 del,
.reveal h3 del {
  color: #0772A1;
}

.reveal section code {
  font-size: 14px;
}

.reveal, .reveal h3 {
  color: #333333;
}

.reveal table {
  font-size: 14px;
  border-collapse: collapse;
  float: left;
}

/*** section background ***/
.section .reveal .state-background {
   background: #0772A1;
}

/*** navigation color ***/
.reveal .controls div.navigate-left,
.reveal .controls div.navigate-left.enabled {
  border-right-color: #0990CC;
}

.reveal .controls div.navigate-right,
.reveal .controls div.navigate-right.enabled {
  border-left-color: #0990CC;
}

.reveal .controls div.navigate-up,
.reveal .controls div.navigate-up.enabled {
  border-bottom-color: #0990CC;
}

.reveal .controls div.navigate-down,
.reveal .controls div.navigate-down.enabled {
  border-top-color: #0990CC;
}

.reveal .controls div.navigate-left.enabled:hover {
  border-right-color: #0BB5FF;
}

.reveal .controls div.navigate-right.enabled:hover {
  border-left-color: #0BB5FF;
}

.reveal .controls div.navigate-up.enabled:hover {
  border-bottom-color: #0BB5FF;
}

.reveal .controls div.navigate-down.enabled:hover {
  border-top-color: #0BB5FF;
}

.reveal .progress span {
  background: #0990CC;
}

.reveal blockquote {
  background: #0772A1;
  color: white;
}
</style>

gravicom
========================================================
author: Andrea Kaplan
date: March 27, 2014
font-family: Helvetica
css: css/charts.css

A web-based tool for community detection in networks

Outline
========================================================

- Introduction/Background
- User Interface
- Demo
- Graphical Devices
- Technical Aspects
- Further Work

Introduction
========================================================
type: section

Who cares and why did we make this?

Networks 
========================================================
- Many relationships easily conceptualized as a graph/network
- A ~~graph~~ is defined as a collection of nodes (entities) and edges (relationships)
- Examples of such relationships include:
  - social networks (sociology)
  - the world wide web (computer science)
  - protein networks (biology)
  
Network Examples
========================================================
<a title="Zachary's Karate Club Network" src="http://www1.ind.ku.dk/complexLearning/zachary1977.pdf"><img alt="Social network of a karate club." src="images/social_network.png" style="width: 32%" /></a>
<a title="Internet as of 2005 By The Opte Project [CC-BY-2.5 (http://creativecommons.org/licenses/by/2.5) or CC-BY-2.5 (http://creativecommons.org/licenses/by/2.5)], via Wikimedia Commons" href="http://commons.wikimedia.org/wiki/File%3AInternet_map_1024_-_transparent.png"><img alt="Internet map 1024 - transparent" src="images/internet_network.png" style="width: 33%;"/></a>
<a title="Treponema pallidum By Häuser et al. [CC-BY-1.0 (http://creativecommons.org/licenses/by/1.0)], via Wikimedia Commons" href="http://commons.wikimedia.org/wiki/File%3AThe_protein_interaction_network_of_Treponema_pallidum.png"><img alt="The protein interaction network of Treponema pallidum" src="images/protein_network.png" style="width: 33%;"/></a>

Community Detection
========================================================
- A ~~community~~ is defined as a group of nodes in a graph that share properties
- ~~Community structure~~ - collection of nodes which are densely linked to nodes within the community and sparsely linked to notes outside
- Current methodology for ~~community detection~~ often involves an algorithmic approach; partitions a graph into node clusters iteratively before stopping criterion
- First define an objective function and then optimize

Modularity
========================================================
- Example objective function: Girvan & Newman’s modularity measure  

\[ Q = \sum\limits_r (e_{rr} - a_r^2)  \]
\(r = \) a community  
\(e_{rr} = \) fraction of links that connect two nodes inside the community  
\(a_r = \) the fraction of links that have one or both vertices inside the community


Modularity (Cont'd)
========================================================
- Interpretation: fraction of edges that connect vertices of the same type minus the expected value of the same quantity in a network with the same community divisions but random edges  

\(Q = 0\):  number of within-community edges no better than random   
\(Q \in [0.3, 0.7]\): strong community structure  
\(Q=1\): maximum value 

Other Objective Functions
========================================================
- Modularity is not the only useful objective function
- Simple proportion: quantification of density within the community vs. sparcity outside

\[ \pi(S) = \frac{\#\text{ of edges within } S}{\#\text{ of edges leaving} S} \]

- Similar idea: Conductance

\[ \phi(S) = \frac{\#\text{ of edges leaving} S}{\sum\limits_{u \in S} \text{degree of } u} \]

Example Objective Functions
========================================================
![Site Components](images/modularity_example.png)
***
<div style="font-size:65%">
\[\begin{matrix}
 e_{AA} = \frac{3}{10} = 0.3 & e_{BB} = \frac{5}{10} = 0.5 \\
 a_{A}^2 = \left(\frac{5}{10}\right)^2 = 0.25 & a_{B}^2 = \left(\frac{7}{10}\right)^2 = 0.49 \\
 e_{AA} - a_A^2 = 0.05 & e_{BB} - a_B^2 = 0.01 \\ ~\\
 Q = 0.06 & 
\end{matrix}\]

<hr>

\[\begin{matrix}
\pi(A) = \frac{3}{2} = 1.5 & \pi(B) = \frac{5}{2} = 2.5
\end{matrix}\]

<hr>

\[\begin{matrix}
\phi(A) = \frac{2}{8} = 0.25 & \phi(B) = \frac{2}{12} = 0.167
\end{matrix}\]
</div>

The Problem
========================================================
- Search for an optimal modularity value is NP-hard 
- The number of possible partitions of the network requires \(2^n\) complexity
- In fact, the optimization of an objective function is typically
an NP-hard problem


Current Solutions
========================================================
- Heuristics used to optimize the objective function in a reasonable amount of time
- Heuristic-based clustering is useful because this offers an automated way to perform community detection 

>The main elements of the problem themselves [graph clustering], i.e. the concepts of community and partition, are not rigorously defined, and require some degree of arbitrariness and/or common sense. (Fortunato, 2010)


- Heuristics are not ~~the~~ solution.

Leverage the Human Visual System
========================================================
- Communities are often fuzzily-defined human concepts
- Address this by adding element of human judgement
- Introduce a novel visualization-based community detection tool, ~~gravicom~~

gravicom Functionality
========================================================
- Allows users to 
  - Visually direct and interact with the steps of community detection
  - Assess the created clusters through visual and quantitative summaries
- Standalone exploratory tool for graph data
- Initial state to be passed to a community detection algorithm in order reduce the complexity of optimization

User Interface
========================================================
type: section

Meet gravicom

Components
========================================================
![Site Components](images/sitecomponents.png)
(1) Control Panel, (2) Data Management, (3) Connection Table, (4) Graph Display, and (5) Tabset

Demo
========================================================
type: section

http://shiny1.iastate.edu/andeek/gravicom  
<small>(must be VPNed to internal ISU network)</small>

Football Example
========================================================
![Site Components](images/football_progression.png)

Football Example (Cont'd)
========================================================
```{r echo=FALSE}

community_stats <- function(path_to_gml){
  require(igraph)
  require(plyr)
  
  df <- get.data.frame(read.graph(path_to_gml, format="gml"), what="both")
  edges_groups <- merge(merge(df$edges, df$vertices[, c("id", "Group")], by.x = "to", by.y = "id", all.x = TRUE),
                        df$vertices[, c("id", "Group")], by.x = "from", by.y = "id", all.x = TRUE)
  names(edges_groups)[3:4] <- c("Group.from", "Group.to")
  
  adj <- as.data.frame(table(edges_groups[,3:4]))
  adj$Ratio <- adj$Freq/sum(adj$Freq)
  
  res <- mdply(unique(c(edges_groups$Group.from, edges_groups$Group.to)), function(x){
    cbind(
      Group = x,
      Proportion = adj[with(adj, Group.from == x & Group.to == x), "Freq"]/(sum(adj[with(adj, Group.from == x & Group.to != x), "Freq"]) + sum(adj[with(adj, Group.from != x & Group.to == x), "Freq"]))
    )
  })
  res$Group <- as.character(res$Group)
  if(nrow(res[substring(res$Group,1,1) == "n",]) > 0) res[substring(res$Group,1,1) == "n",]$Group<-"independent"
  res$Modularity <- diag(table(edges_groups[,3:4])/sum(table(edges_groups[,3:4]))) - (rowSums(table(edges_groups[,3:4])/sum(table(edges_groups[,3:4]))))^2
  
  return(res)
}
```

```{r echo=FALSE, results='asis'}
library(igraph)
library(plyr)
library(scales)
library(xtable)
football.df <- get.data.frame(read.graph("data/football_network.gml", format="gml"), what="vertices")

#put all ungrouped as own group -- corresponds to value 5
football.df[substring(football.df$Group,1,1) == "n",]$Group<-"independent"

#create map from gravicom to original by most mapped
map <- ddply(football.df, .(Group), summarise, orig.grp = names(sort(-table(value)))[1])
football.df.m <- merge(football.df, map, by = "Group", all.x=TRUE)

idx <- with(football.df.m, which(value != orig.grp))
stats <- community_stats("data/football_network.gml")

football.df.m <- merge(football.df.m, stats, by="Group", all.x=TRUE)
football.df.m$label[idx] <- sprintf("<i><del>%s</del></i>",football.df.m$label[idx]) 
football.df.m$Proportion <- as.numeric(as.character(football.df.m$Proportion))

results <- ddply(football.df.m, .(orig.grp), summarise, 
                 teams=paste(label, collapse=", "), 
                 prop=min(Proportion),
                 perc.right=percent(1 - sum(value != orig.grp)/length(orig.grp)))
results <- results[with(results, order(as.numeric(orig.grp))),]
results$Conference <- c("ACC", "Big East", "Big 10", "Big 12", "C-USA", "Independent", "MAC", "Mountain West", "Pac-10", "SEC", "Big West", "WAC" )

results <- results[,c(5,2,3,4)]
colnames(results) <- c("Conference", "Teams Identified", "Proportion", "Accuracy")
results$`Teams Identified` <- gsub('(.)([A-Z])',"\\1 \\2", results$`Teams Identified`)

#percent school misspecified
percent_correct <- 1 - sum(football.df.m$value != football.df.m$orig.grp)/nrow(football.df)

print(xtable(results[with(results, order(-Proportion)),][1:6,], align=c("c", "c","p{10cm}","c", "c"), label='tab:football_final'), include.rownames=FALSE, table.placement='H', type="html", sanitize.text.function = function(x)gsub('&lt', '<', gsub('&gt', '>', x)))
```

Football Example (Cont'd)
========================================================
```{r echo=FALSE, results='asis'}
print(xtable(results[with(results, order(-Proportion)),][7:nrow(results),], align=c("c", "c","p{10cm}","c", "c"), label='tab:football_final'), include.rownames=FALSE, table.placement='H', type="html", sanitize.text.function = function(x)gsub('&lt', '<', gsub('&gt', '>', x)))
```
- Through manual specification of conferences, we were able to correctly classify `r round(100*percent_correct, 2)` % of the football teams into their conferences. 

Political Books Example
========================================================
- Political books co-purchased close to the 2004 United States presidential election and sold on Amazon.com
![Political Books](images/polbooks_1.png)

Political Books Example (Cont'd)
========================================================
![Political Books Grouped](images/polbooks_2.png)

Poltical Books Example (Cont'd)
========================================================
```{r echo=FALSE, results='asis'}
polbooks.df <- get.data.frame(read.graph("data/polbooks_network.gml", format="gml"), what="vertices")

#create map from gravicom to original by most mapped
map <- ddply(polbooks.df, .(Group), summarise, orig.grp = names(sort(-table(value)))[1])
polbooks.df.m <- merge(polbooks.df, map, by = "Group", all.x=TRUE)

stats <- community_stats("data/polbooks_network.gml")
polbooks.df.m <- merge(polbooks.df.m, stats, by="Group", all.x=TRUE)

idx <- with(polbooks.df.m, which(value != orig.grp))
polbooks.df.m$label[idx] <- sprintf("<i><del>%s</del></i>",polbooks.df.m$label[idx]) 
polbooks.df.m$Proportion <- as.numeric(as.character(polbooks.df.m$Proportion))

results_pol <- ddply(polbooks.df.m, .(orig.grp), summarise, 
                 books=paste(label, collapse=", "), 
                 prop=min(Proportion),
                 perc.right=percent(1 - sum(value != orig.grp)/length(orig.grp)))
results_pol$designation <- c("Conservative", "Liberal", "Neutral")

results_pol <- results_pol[,c(5,2,3,4)]
colnames(results_pol) <- c("Classification", "Books Identified", "Proportion", "Accuracy")

#percent books misspecified
percent_correct <- 1 - sum(polbooks.df.m$value != polbooks.df.m$orig.grp)/nrow(polbooks.df)

print(xtable(results_pol[with(results_pol, order(-Proportion)),][1,], align=c("c", "c","p{10cm}","c", "c"), label='tab:polbooks_final'), include.rownames=FALSE, table.placement='H', type="html", sanitize.text.function = function(x)gsub('&lt', '<', gsub('&gt', '>', x)))
```

Political Books Example (Cont'd)
========================================================
```{r echo=FALSE, results='asis'}
print(xtable(results_pol[with(results_pol, order(-Proportion)),][2,], align=c("c", "c","p{10cm}","c", "c"), label='tab:polbooks_final'), include.rownames=FALSE, table.placement='H', type="html", sanitize.text.function = function(x)gsub('&lt', '<', gsub('&gt', '>', x)))
```

Political Books Example (Cont'd)
========================================================
```{r echo=FALSE, results='asis'}
print(xtable(results_pol[with(results_pol, order(-Proportion)),][3,], align=c("c", "c","p{10cm}","c", "c"), label='tab:polbooks_final'), include.rownames=FALSE, table.placement='H', type="html", sanitize.text.function = function(x)gsub('&lt', '<', gsub('&gt', '>', x)))
```
- Correctly classified `r round(100*percent_correct, 2)` %  of the books into the categories created by the author of the data set.

Graphical Devices
========================================================
type: section

Theory behind the curtain

Importance of Graph Layout
========================================================
- ~~Graph layout~~ is an assignment of a Cartesian coordinate to each node for display in 2D or 3D
- Layout of a graph significantly affects the number of communities that users detect within a graph
- Humans used to detect communities \( \Rightarrow \) special attention needs to be paid to the layout being used
- Location of a node spatially relative to other nodes in a cluster has a significant effect on user: "adjacent nodes must be placed near to each other if possible" (McGrath, Blythe, and Krackhardt, 1996)

Force-Directed Layout
========================================================
- Physics based algorithm for graph drawing
- Repulsive forces (charged particles) used to separate all pairs of nodes
- Links are fixed-distance geometric constraints 
- Groups of nodes sharing multiple edges are pulled in closer proximity
- Pseudo-gravity force keeps nodes centered in the visible area and avoids expulsion of disconnected subgraphs

Graph Simplification
========================================================
- Difficult to glean meaning from a visual representation in large/complex graphs 
- Replace repeated patterns in a graph by a representation, to simplify a network
- Fewer nodes and edges to display \( \Rightarrow \) visual complexity of the graph visualization is greatly reduced
- Allows the user to analyze the network structure more accurately

Technical Aspects
========================================================
type: section

What makes it tick?


Page Lifecycle
========================================================
![Integrated Algorithm](images/pagelifecycle.png)


Tools
========================================================
class: particle-chart

- ~~Shiny~~: Server-client interaction
- ~~D3~~: User interface and graph layout
- ~~igraph~~: Data formatting

Tools (Cont'd)
========================================================
![Integrated Algorithm](images/clientserverflow.png)

Data Formatting
========================================================
GML file structure:
```{r gml, results='markup', echo=FALSE}
cat( readLines( "data/sample.gml" ) , sep = "\n" )
```

JSON file structure:
```{r json, results='markup', echo=FALSE}
cat( readLines( "data/sample.json" ) , sep = "\n" )
```

Further Work
========================================================
type: section

Possible extensions to gravicom

Integrated Algorithmic Community Detection
========================================================
- Combine the benefits of human detection of communities with algorithmic detection
- Visual detection of communities serves as an initialization step
- Pass to iterative algorithm
- User tracks progress and has power to dynamically set stopping criterion

How would it work?
=======================================================
![Integrated Algorithm](images/integrated_algorithm.png)

Dynamic Temporal Graph Visualization
========================================================
- View a dynamic graph across time -- how the edges change between nodes 
- Detect time-dependent communities
- Add optional node labels to track progress

Questions?
========================================================
type: section

Thank you!

<script type="text/javascript" src="scripts/jquery.min.js"></script>
<script type="text/javascript" src="scripts/d3.v3.min.js"></script>
<script type="text/javascript" src="scripts/charts.js"></script>
<script>
$(document).ready(function() { 
  (particleChart())() ;   
});
</script>

